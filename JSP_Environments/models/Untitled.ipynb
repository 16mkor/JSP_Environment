{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "978e8eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "420b496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_toeplitz_matrix(m):\n",
    "    N, L = m.shape\n",
    "    diagonal = torch.arange(N)\n",
    "    indices = diagonal.view(-1, 1) - diagonal\n",
    "    b = m[indices]\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3737946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "\n",
    "toeplitz_matrix = create_toeplitz_matrix(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f13b61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [7, 8, 9],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[4, 5, 6],\n",
      "         [1, 2, 3],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[7, 8, 9],\n",
      "         [4, 5, 6],\n",
      "         [1, 2, 3]]])\n"
     ]
    }
   ],
   "source": [
    "print(toeplitz_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16c287da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [4., 1., 0.],\n",
      "        [7., 4., 1.]])\n"
     ]
    }
   ],
   "source": [
    "def create_toeplitz_matrix(m):\n",
    "    N, L = m.shape\n",
    "    b = torch.zeros((N, N))\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i >= j:\n",
    "                b[i, j] = m[i - j, 0]\n",
    "\n",
    "    return b\n",
    "\n",
    "m = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "\n",
    "toeplitz_matrix = create_toeplitz_matrix(m)\n",
    "print(toeplitz_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de8cbb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [3, 1, 2],\n",
      "         [2, 3, 1]],\n",
      "\n",
      "        [[4, 5, 6],\n",
      "         [6, 4, 5],\n",
      "         [5, 6, 4]],\n",
      "\n",
      "        [[7, 8, 9],\n",
      "         [9, 7, 8],\n",
      "         [8, 9, 7]]])\n"
     ]
    }
   ],
   "source": [
    "def create_toeplitz_matrix(m):\n",
    "    N, L = m.shape\n",
    "    diagonal = torch.arange(L)\n",
    "    indices = diagonal.view(1, -1) - diagonal.view(-1, 1)\n",
    "    b = m[:, indices]\n",
    "\n",
    "    return b\n",
    "\n",
    "m = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "\n",
    "toeplitz_matrix = create_toeplitz_matrix(m)\n",
    "print(toeplitz_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e789ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5 6 7 8 9]\n",
      " [2 1 2 3 4 5 6 7 8]\n",
      " [3 2 1 2 3 4 5 6 7]\n",
      " [4 3 2 1 2 3 4 5 6]\n",
      " [5 4 3 2 1 2 3 4 5]\n",
      " [6 5 4 3 2 1 2 3 4]\n",
      " [7 6 5 4 3 2 1 2 3]\n",
      " [8 7 6 5 4 3 2 1 2]\n",
      " [9 8 7 6 5 4 3 2 1]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import toeplitz\n",
    "\n",
    "m = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "\n",
    "toeplitz_matrix = toeplitz(m)\n",
    "print(toeplitz_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f318a5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [128, 128, 1, 1], but got 3-dimensional input of size [1, 1, 128] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-77375999860a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Perform the 1x1 convolution to multiply the attention tensor with the Toeplitz matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtoeplitz_expanded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 442\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [128, 128, 1, 1], but got 3-dimensional input of size [1, 1, 128] instead"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.linalg as linalg\n",
    "\n",
    "# Create the attention tensor of shape (1, 1, 128)\n",
    "attention = torch.ones((1, 1, 128))\n",
    "\n",
    "# Generate the Toeplitz matrix using scipy.linalg.toeplitz\n",
    "toeplitz_matrix = linalg.toeplitz(range(128))\n",
    "\n",
    "# Convert the Toeplitz matrix to a torch tensor\n",
    "toeplitz_tensor = torch.from_numpy(toeplitz_matrix).float()\n",
    "\n",
    "# Expand dimensions to match the attention tensor shape\n",
    "toeplitz_expanded = toeplitz_tensor.expand(1, 1, 128, 128)\n",
    "\n",
    "# Define the convolution layer with 128 input channels and 128 output channels\n",
    "conv = nn.Conv2d(128, 128, kernel_size=1, stride=1)\n",
    "\n",
    "# Perform the 1x1 convolution to multiply the attention tensor with the Toeplitz matrix\n",
    "result = conv(attention) * toeplitz_expanded\n",
    "\n",
    "print(result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fa3bcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c664c7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0aa643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
