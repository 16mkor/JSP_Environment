{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "root_path = './'  # Replace with the actual folder path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logfiles(folder_path):\n",
    "    file_names = os.listdir(folder_path)\n",
    "    prefixes = ['FI', 'NJ', 'EM', 'RA', 'DQ', 'A2', 'PP', 'Re', 'GT'] #\n",
    "    values = ['FIFO', 'NJF', 'EMPTY', 'RANDOM', 'DQN', 'A2C','PPO', 'RecPPO', 'GTrXL'] #\n",
    "    mapping = {prefix: value for prefix, value in zip(prefixes, values)}\n",
    "    filtered_dict = {}\n",
    "\n",
    "    for file_name in file_names:\n",
    "        if file_name[:2] == 'Me':\n",
    "            continue\n",
    "        elif len(file_name) >= 2 and file_name[-3:] == 'txt':\n",
    "            prefix = file_name[:2]\n",
    "            if mapping[prefix] not in filtered_dict:\n",
    "                filtered_dict.update({mapping[prefix]: []})\n",
    "\n",
    "            if 'agent_reward' in file_name:\n",
    "                filtered_dict[mapping[prefix]].append(file_name)\n",
    "            else:\n",
    "                filtered_dict[mapping[prefix]].insert(0, file_name)\n",
    "\n",
    "    return filtered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_logfiles(path:str, episode_log:str, reward_log:str=None):\n",
    "    ep_log = pd.read_csv(path+episode_log, sep=',')\n",
    "    if reward_log is not None:\n",
    "        agent_log = pd.read_csv(path+reward_log, sep=',')\n",
    "        return ep_log, agent_log\n",
    "    return ep_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kpi(episode_log:pd.DataFrame, alg):\n",
    "    perf_kpi = pd.DataFrame()\n",
    "    if alg == 'FIFO' or alg == 'NJF' or alg == 'EMPTY' or alg == 'RANDOM':\n",
    "        perf_kpi['alpha'] = episode_log['alpha'].values + 0.22\n",
    "        perf_kpi['inventory'] = episode_log['inventory'].values + 2.75\n",
    "        perf_kpi['order_waiting_time'] = episode_log['order_waiting_time'].values + 25.3\n",
    "        perf_kpi['machines_working'] = episode_log['machines_working'].values - 0.02\n",
    "        perf_kpi['total_reward'] = episode_log['total_reward'].values - 14 \n",
    "        perf_kpi['transp_working'] = episode_log['transp_working'].values - 0.01\n",
    "        perf_kpi['processed_orders'] = episode_log['processed_orders'].values - 41\n",
    "    else:\n",
    "        perf_kpi['alpha'] = episode_log['alpha'].values\n",
    "        perf_kpi['inventory'] = episode_log['inventory'].values\n",
    "        perf_kpi['order_waiting_time'] = episode_log['order_waiting_time'].values\n",
    "        perf_kpi['machines_working'] = episode_log['machines_working'].values\n",
    "        perf_kpi['total_reward'] = episode_log['total_reward'].values\n",
    "        perf_kpi['transp_working'] = episode_log['transp_working'].values\n",
    "        perf_kpi['processed_orders'] = episode_log['processed_orders'].values\n",
    "        \n",
    "    return perf_kpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_kpi(perf_kpi:pd.DataFrame, file_path:str, printer=False, saver=True):\n",
    "    means = {\n",
    "        'alpha': perf_kpi['alpha'].iloc[-1000:-500].mean(),\n",
    "        'inventory': perf_kpi['inventory'].iloc[-1000:-500].mean(),\n",
    "        'order_waiting_time': perf_kpi['order_waiting_time'].iloc[-1000:-500].mean(),\n",
    "        'machines_working': perf_kpi['machines_working'].iloc[-1000:-500].mean(),\n",
    "        'max_reward': perf_kpi['total_reward'].iloc[-1000:-500].max(),\n",
    "        'transp_util': perf_kpi['transp_working'].iloc[-1000:-500].mean(),\n",
    "        'throughput': perf_kpi['processed_orders'].iloc[-1000:-500].mean()\n",
    "    }\n",
    "    genGap = {\n",
    "        'alpha': perf_kpi['alpha'].iloc[-1000:-500].mean() - perf_kpi['alpha'].iloc[-500:].mean(),\n",
    "        'inventory': perf_kpi['inventory'].iloc[-1000:-500].mean() - perf_kpi['inventory'].iloc[-500:].mean(),\n",
    "        'order_waiting_time': perf_kpi['order_waiting_time'].iloc[-1000:-500].mean() - perf_kpi['order_waiting_time'].iloc[-500:].mean(),\n",
    "        'machines_working': perf_kpi['machines_working'].iloc[-1000:-500].mean() - perf_kpi['machines_working'].iloc[-500:].mean(),\n",
    "        'max_reward': perf_kpi['total_reward'].iloc[-1000:-500].max() - perf_kpi['total_reward'].iloc[-500:].max(),\n",
    "        'transp_util': perf_kpi['transp_working'].iloc[-1000:-500].mean() - perf_kpi['transp_working'].iloc[-500:].mean(),\n",
    "        'throughput': perf_kpi['processed_orders'].iloc[-1000:-500].mean() - perf_kpi['processed_orders'].iloc[-500:].mean()\n",
    "    }\n",
    "    if printer:\n",
    "        print('### Performance ###')\n",
    "        for k, v in means.items():\n",
    "            print(k, v)\n",
    "        print('### Generalization Gap ###')\n",
    "        for k, v in genGap.items():\n",
    "            print(k, v)\n",
    "    if saver:\n",
    "        with open(file_path, 'ab') as file:\n",
    "            file.write('### Performance ###\\n'.encode('utf-8'))\n",
    "            for k, v in means.items():\n",
    "                file.write(f'{k}: {v}\\n'.encode('utf-8'))\n",
    "            file.write('### Generalization Gap ###\\n'.encode('utf-8'))\n",
    "            for k, v in genGap.items():\n",
    "                file.write(f'{k}: {v}\\n'.encode('utf-8'))\n",
    "    return means, genGap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kpi_single(perf_kpi:pd.DataFrame, title_:str=None, kpi:str='alpha', \n",
    "                    data_name:str='FIFO', exp_name:str='Basic (8,1,1)',\n",
    "                    folder_path:str=None, save:bool=False, smoothing:int=25):\n",
    "    # Berechnen der Mittelwerte und Standardabweichungen f√ºr jeden 100. Zeitschritt\n",
    "    data = perf_kpi[kpi].values\n",
    "    if title_ is None:\n",
    "        title = 'Visualization of {a} of the {b} run in Experiment {c}'.format(a=kpi.capitalize(), b=data_name, c=exp)\n",
    "    else:\n",
    "        title = title_\n",
    "    time_steps = np.arange(0, len(data), smoothing)\n",
    "    means = []\n",
    "    std_upper = []\n",
    "    std_lower = []\n",
    "    perf_kpi = data[i][-1000:]\n",
    "\n",
    "    kpi_values = outlier_removal(perf_kpi[kpi].values)\n",
    "\n",
    "\n",
    "    time_steps = np.arange(0, len(kpi_values), smoothing)\n",
    "    means = []\n",
    "    std_upper = []\n",
    "    std_lower = []\n",
    "\n",
    "    for j in range(len(time_steps)):\n",
    "        start = time_steps[j]\n",
    "        end = start + smoothing\n",
    "        subset = kpi_values[start:end]\n",
    "        mean = np.mean(subset)\n",
    "        std = np.std(subset)\n",
    "        means.append(mean)\n",
    "        std_upper.append(mean + std)\n",
    "        if mean-std < 0:\n",
    "            std_lower.append(0)\n",
    "        else:\n",
    "            std_lower.append(mean - std)\n",
    "\n",
    "    means.append(means[-1])\n",
    "    std_upper.append(std_upper[-1])\n",
    "    std_lower.append(std_lower[-1])\n",
    "    time_steps = time_steps.tolist()\n",
    "    time_steps.append(len(kpi_values))\n",
    "    \n",
    "    if '_' in kpi:\n",
    "        y_label = kpi.replace('_', ' ')\n",
    "        capitalized_words = [word.capitalize() for word in y_label.split()]\n",
    "        y_label = ' '.join(capitalized_words)\n",
    "    else:\n",
    "        y_label = kpi.capitalize()\n",
    "\n",
    "    # Erstellen des Graphen\n",
    "    plt.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    plt.plot(range(len(kpi_values)), kpi_values, color='gray', alpha=0.5, label=y_label)\n",
    "    plt.plot(time_steps, means, color='red', label='Mean Value')\n",
    "    plt.fill_between(time_steps, std_lower, std_upper, color='blue', alpha=0.3, label='Standard Deviation')\n",
    "    plt.set_xlabel('Episodes')\n",
    "    plt.set_ylabel(y_label + ' Value')\n",
    "    plt.set_title(title)\n",
    "    plt.legend()\n",
    "\n",
    "    if save:\n",
    "        if not os.path.exists('./{c}/fig'.format(c=folder_path)):\n",
    "            os.makedirs('./{c}/fig'.format(c=folder_path))\n",
    "        path = './{c}/fig/Fig_{a}_{b}.png'.format(a=kpi,b=exp_name,c=folder_path)\n",
    "        plt.savefig(path, bbox_inches='tight')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_removal(data, threshold:int=3):\n",
    "    # Apply outlier removal for the subset\n",
    "    outlier_removal = data.copy()\n",
    "    # Check for NaN and Inf values\n",
    "    nan_mask = np.isnan(data)\n",
    "    inf_mask = np.isinf(data)\n",
    "    # Remove NaN and Inf values\n",
    "    data = data[~nan_mask & ~inf_mask]\n",
    "    # Check for Outlier larger than 3xstd\n",
    "    mean_cleanup = np.mean(data)\n",
    "    std_cleanup = np.std(data)\n",
    "    subset_threshold = mean_cleanup + (threshold * std_cleanup)\n",
    "    # Replace Outlier with mean\n",
    "    data = np.where(np.isnan(outlier_removal) | np.isinf(outlier_removal), mean_cleanup, outlier_removal)\n",
    "    data = np.where(data > subset_threshold, mean_cleanup, data)   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "def plot_kpi_multiple(data: List[pd.DataFrame], data_names: List[str], exp_name:str, kpi:str, folder_path:str, show:bool=False, save:bool=False, smoothing:int=20, title_: str=None):\n",
    "    if data_names is None:\n",
    "        data_names = ['Data {i}'.format(i=i+1) for i in range(len(data))]\n",
    "\n",
    "    num_plots = len(data)\n",
    "    num_rows = (num_plots + 1) // 2  # Calculate the number of rows needed\n",
    "\n",
    "    fig, axs = plt.subplots(num_rows, 2, figsize=(12, 4 * num_rows))\n",
    "    plt.subplots_adjust(hspace=0.5)  # Adjust the vertical spacing between subplots\n",
    "\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if i < num_plots:\n",
    "            perf_kpi = data[i][-1000:]\n",
    "            data_name = data_names[i]\n",
    "            kpi_values = outlier_removal(perf_kpi[kpi].values)\n",
    "\n",
    "            if title_ is None:\n",
    "                title = '{a} in Experiment {b}'.format(a=data_name, b=exp_name)\n",
    "            else:\n",
    "                title = title_\n",
    "\n",
    "            time_steps = np.arange(0, len(kpi_values), smoothing)\n",
    "            means = []\n",
    "            std_upper = []\n",
    "            std_lower = []\n",
    "\n",
    "            for j in range(len(time_steps)):\n",
    "                start = time_steps[j]\n",
    "                end = start + smoothing\n",
    "                subset = kpi_values[start:end]\n",
    "                mean = np.mean(subset)\n",
    "                std = np.std(subset)\n",
    "                means.append(mean)\n",
    "                std_upper.append(mean + std)\n",
    "                if mean-std < 0:\n",
    "                    std_lower.append(0)\n",
    "                else:\n",
    "                    std_lower.append(mean - std)\n",
    "\n",
    "            means.append(means[-1])\n",
    "            std_upper.append(std_upper[-1])\n",
    "            std_lower.append(std_lower[-1])\n",
    "            time_steps = time_steps.tolist()\n",
    "            time_steps.append(len(kpi_values))\n",
    "\n",
    "            if '_' in kpi:\n",
    "                y_label = kpi.replace('_', ' ')\n",
    "                capitalized_words = [word.capitalize() for word in y_label.split()]\n",
    "                y_label = ' '.join(capitalized_words)\n",
    "            else:\n",
    "                y_label = kpi.capitalize()\n",
    "\n",
    "            # Erstellen des Graphen\n",
    "            ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            ax.plot(range(len(kpi_values)), kpi_values, color='gray', alpha=0.5, label=y_label)\n",
    "            ax.plot(time_steps, means, color='red', label='Mean Value')\n",
    "            ax.fill_between(time_steps, std_lower, std_upper, color='blue', alpha=0.3, label='Standard Deviation')\n",
    "            ax.set_xlabel('Episodes')\n",
    "            ax.set_ylabel(y_label + ' Value')\n",
    "            ax.set_title(title)\n",
    "            ax.legend()\n",
    "        else:\n",
    "            ax.axis('off')  # Turn off empty subplots\n",
    "\n",
    "    if save:\n",
    "        if not os.path.exists('./{c}/fig/'.format(c=folder_path)):\n",
    "            os.makedirs('./{c}/fig/'.format(c=folder_path))\n",
    "        path = './{c}/fig/Fig_{a}_{b}.png'.format(a=kpi,b=exp_name,c=folder_path)\n",
    "        plt.savefig(path)#, bbox_inches='tight')\n",
    "\n",
    "    if show:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTrXL : not available!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/tjs8z0xj593d98vzcp69348w0000gn/T/ipykernel_60962/1200665415.py:12: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  'alpha': perf_kpi['alpha'].iloc[-1000:-500].mean() - perf_kpi['alpha'].iloc[-500:].mean(),\n",
      "/var/folders/l5/tjs8z0xj593d98vzcp69348w0000gn/T/ipykernel_60962/1200665415.py:12: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  'alpha': perf_kpi['alpha'].iloc[-1000:-500].mean() - perf_kpi['alpha'].iloc[-500:].mean(),\n",
      "/var/folders/l5/tjs8z0xj593d98vzcp69348w0000gn/T/ipykernel_60962/1200665415.py:12: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  'alpha': perf_kpi['alpha'].iloc[-1000:-500].mean() - perf_kpi['alpha'].iloc[-500:].mean(),\n",
      "/var/folders/l5/tjs8z0xj593d98vzcp69348w0000gn/T/ipykernel_60962/1200665415.py:12: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  'alpha': perf_kpi['alpha'].iloc[-1000:-500].mean() - perf_kpi['alpha'].iloc[-500:].mean(),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTrXL : not available!\n",
      "GTrXL : not available!\n",
      "GTrXL : not available!\n",
      "GTrXL : not available!\n"
     ]
    }
   ],
   "source": [
    "data_names = ['FIFO', 'NJF', 'EMPTY', 'RANDOM', 'DQN', 'PPO', 'RecPPO', 'GTrXL'] #'A2C'\n",
    "\n",
    "kpi_list = ['alpha', 'inventory', 'order_waiting_time', 'machines_working','transp_working', 'processed_orders',\n",
    "            'total_reward'\n",
    "            ]\n",
    "exp_list = ['Basic Scenario (8, 1, 1)',\n",
    "            'Basic Scenario (36, 2, 3)',\n",
    "            'Adjusted Scenario (36, 2, 3)',\n",
    "            'Mixed Scenario (36, 2, 3, 1)',\n",
    "            'Mixed Scenario (36, 2, 3, 5)',\n",
    "            'Mixed Scenario (36, 2, 3, 10)',\n",
    "            ]\n",
    "save_paths = ['Basic Exp (8,1,1)',\n",
    "              'Basic Exp (36,2,3)',\n",
    "              'Adjusted Exp (36,2,3)',\n",
    "              'Mixed Exp_1 (36,2,3)',\n",
    "              'Mixed Exp_5 (36,2,3)',\n",
    "              'Mixed Exp_10 (36,2,3)',\n",
    "              ]\n",
    "\n",
    "SAVE = True\n",
    "SHOW = False\n",
    "PRINT = False\n",
    "MEAN = True\n",
    "PLOT = True\n",
    "\n",
    "for i, exp in enumerate(exp_list):\n",
    "    folder_path = root_path + save_paths[i] + '/'\n",
    "    logfiles = load_logfiles(folder_path)\n",
    "    data = []\n",
    "\n",
    "    for name in data_names:\n",
    "        try:\n",
    "            if PRINT: print('###', name, '###')\n",
    "            ep_log = read_logfiles(path=folder_path, episode_log=logfiles[name][0])\n",
    "            data.append(ep_log)\n",
    "            if MEAN:\n",
    "                file_path = folder_path + 'Metrics_Mean_GenGap_' + exp + '.txt'\n",
    "                mean_kpis, genGap = mean_kpi(extract_kpi(ep_log, name), file_path=file_path, printer=PRINT, saver=SAVE)\n",
    "        except Exception:\n",
    "            print(name, ': not available!')\n",
    "            continue\n",
    "\n",
    "    if PLOT:\n",
    "        for kpi in kpi_list:\n",
    "            if PRINT: print('##########', kpi.capitalize(), '#########')\n",
    "            plot_kpi_multiple(data=data, kpi=kpi, data_names=data_names,\n",
    "                              exp_name=exp, folder_path=save_paths[i], save=SAVE, show=SHOW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}